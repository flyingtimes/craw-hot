#!/usr/bin/env python3
"""
é€šè¿‡æµè§ˆå™¨å·¥å…·æŠ“å– X.com å¸–å­
"""

import json
import subprocess
from datetime import datetime

def run_browser_command(cmd):
    """è¿è¡Œ openclaw browser å‘½ä»¤"""
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=30
        )
        if result.returncode == 0:
            return result.stdout
        return None
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return None

def fetch_posts(count=20):
    """èŽ·å–å¸–å­"""
    posts = []

    # å…ˆå¯¼èˆªåˆ° x.com
    print("å¯¼èˆªåˆ° x.com...")
    run_browser_command([
        "openclaw", "browser", "navigate",
        "--profile", "chrome",
        "--targetUrl", "https://x.com/home"
    ])

    # èŽ·å–å¸–å­æ•°é‡
    article_count = 6  # é»˜è®¤å€¼
    print("æ£€æŸ¥å¸–å­æ•°é‡...")
    result = run_browser_command([
        "openclaw", "browser", "act",
        "--profile", "chrome",
        "--request", json.dumps({"kind": "evaluate", "fn": "document.querySelectorAll('article').length"})
    ])

    if result:
        try:
            data = json.loads(result)
            article_count = int(data.get("result", 6))
            print(f"æ‰¾åˆ° {article_count} ä¸ªå¸–å­")
        except:
            article_count = 6
            print(f"é»˜è®¤è¯»å– {article_count} ä¸ªå¸–å­")

    # æå–æ¯ä¸ªå¸–å­çš„ä¿¡æ¯
    for i in range(min(article_count, count)):
        try:
            # èŽ·å–æ–‡æœ¬å†…å®¹
            text_result = run_browser_command([
                "openclaw", "browser", "act",
                "--profile", "chrome",
                "--request", json.dumps({
                    "kind": "evaluate",
                    "fn": f"document.querySelectorAll('article')[{i}].querySelector('[data-testid=\"tweetText\"]')?.textContent || ''"
                })
            ])

            # èŽ·å–ä½œè€…
            author_result = run_browser_command([
                "openclaw", "browser", "act",
                "--profile", "chrome",
                "--request", json.dumps({
                    "kind": "evaluate",
                    "fn": f"document.querySelectorAll('article')[{i}].querySelector('header a')?.textContent || 'Unknown'"
                })
            ])

            # èŽ·å–æ—¶é—´
            time_result = run_browser_command([
                "openclaw", "browser", "act",
                "--profile", "chrome",
                "--request", json.dumps({
                    "kind": "evaluate",
                    "fn": f"document.querySelectorAll('article')[{i}].querySelector('time')?.getAttribute('datetime') || ''"
                })
            ])

            text = ""
            if text_result:
                try:
                    data = json.loads(text_result)
                    text = data.get("result", "")
                except:
                    pass

            author = "Unknown"
            if author_result:
                try:
                    data = json.loads(author_result)
                    author = data.get("result", "Unknown")
                except:
                    pass

            time_str = ""
            if time_result:
                try:
                    data = json.loads(time_result)
                    time_str = data.get("result", "")
                except:
                    pass

            if text:
                posts.append({
                    "author": author.strip(),
                    "text": text.strip(),
                    "time": time_str,
                    "index": i + 1
                })
                print(f"âœ“ èŽ·å–ç¬¬ {i+1} æ¡å¸–å­: {author[:30]}")

        except Exception as e:
            print(f"èŽ·å–ç¬¬ {i+1} æ¡å¸–å­æ—¶å‡ºé”™: {e}")
            continue

    return posts

def main():
    print(f"\n{'='*60}")
    print("X.com å¸–å­æŠ“å–")
    print(f"{'='*60}\n")

    posts = fetch_posts(20)

    print(f"\n{'='*60}")
    print(f"âœ… æˆåŠŸèŽ·å– {len(posts)} ä¸ªå¸–å­")
    print(f"{'='*60}\n")

    # ä¿å­˜åˆ°æ–‡ä»¶
    output_file = "/Users/clark/clawd/x-posts-today.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(posts, f, ensure_ascii=False, indent=2)
    print(f"ðŸ“„ æ•°æ®å·²ä¿å­˜åˆ°: {output_file}\n")

    # æ˜¾ç¤ºé¢„è§ˆ
    if posts:
        print("ðŸ“° å¸–å­é¢„è§ˆï¼ˆå‰10æ¡ï¼‰ï¼š\n")
        for post in posts[:10]:
            print(f"{post['index']}. {post['author']}")
            preview = post['text'][:150] + "..." if len(post['text']) > 150 else post['text']
            print(f"   {preview}\n")

if __name__ == "__main__":
    main()